{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VX9ot7X2U9yO"},"outputs":[],"source":["!pip install --quiet --upgrade pip\n","!pip install fiona\n","!pip install rasterio --quiet\n","!pip install \"apache-beam[gcp]>=2.50.0\"\n","!pip install \"earthengine-api>=1.5.9\"\n","!pip install \"folium>=0.19.5\"\n","!pip install \"google-cloud-aiplatform>=1.47.0\"\n","!pip install \"imageio>=2.36.1\"\n","!pip install \"plotly>=5.15.0\"\n","!pip install \"tensorflow>=2.16.1\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86838,"status":"ok","timestamp":1763478042769,"user":{"displayName":"Saad Kaka","userId":"12542036726510373387"},"user_tz":300},"id":"pgMqF8QBcTow","outputId":"f2818703-8a7e-4f50-eb8e-5a4e8420ef50"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFORMATION: Project 'saadwetlands' has no 'environment' tag set. Use either 'Production', 'Development', 'Test', or 'Staging'. Add an 'environment' tag using `gcloud resource-manager tags bindings create`.\n","Updated property [core/project].\n","Bucket: gs://saadwetlands-bucket/\n","Downloading all .tif files from: gs://saadwetlands-bucket/pixel_data/\n","This may take a while depending on file sizes...\n","Copying gs://saadwetlands-bucket/pixel_data/ON.tif...\n","Copying gs://saadwetlands-bucket/pixel_data/MB.tif...\n","Copying gs://saadwetlands-bucket/pixel_data/NSBOX_LABELS.tif...\n","Copying gs://saadwetlands-bucket/pixel_data/NSBOX_64.tif...\n","Copying gs://saadwetlands-bucket/pixel_data/BC.tif...\n","Copying gs://saadwetlands-bucket/pixel_data/ONBOX_64.tif...\n","Copying gs://saadwetlands-bucket/pixel_data/ONBOX_LABELS.tif...\n","| [7/7 files][  1.2 GiB/  1.2 GiB] 100% Done  76.7 MiB/s ETA 00:00:00           \n","Operation completed over 7 objects/1.2 GiB.                                      \n","\n","Download complete!\n","\n","Downloaded files:\n","-rw-r--r-- 1 root root 8.7M Nov 18 15:00 /content/data/BC.tif\n","-rw-r--r-- 1 root root  30M Nov 18 15:00 /content/data/MB.tif\n","-rw-r--r-- 1 root root 553M Nov 18 15:00 /content/data/NSBOX_64.tif\n","-rw-r--r-- 1 root root 669K Nov 18 15:00 /content/data/NSBOX_LABELS.tif\n","-rw-r--r-- 1 root root 598M Nov 18 15:00 /content/data/ONBOX_64.tif\n","-rw-r--r-- 1 root root 971K Nov 18 15:00 /content/data/ONBOX_LABELS.tif\n","-rw-r--r-- 1 root root  12M Nov 18 15:00 /content/data/ON.tif\n"]}],"source":["from google.colab import auth\n","import os\n","import ee\n","import google.auth\n","import pandas as pd\n","import numpy as np\n","import rasterio\n","from google.cloud import storage\n","\n","# AUTHENTICATE\n","auth.authenticate_user()\n","project = \"saadwetlands\"\n","bucket = \"saadwetlands-bucket\"\n","location = \"northamerica-northeast1\"\n","os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project\n","!gcloud config set project {project}\n","credentials, _ = google.auth.default()\n","\n","ee.Initialize(\n","    credentials.with_quota_project(None),\n","    project=project,\n","    opt_url=\"https://earthengine-highvolume.googleapis.com\",\n",")\n","\n","# DIRECTORIES\n","!mkdir -p /content/data/\n","source_path = f\"gs://{bucket}/pixel_data/\"\n","local_path = \"/content/data/\"\n","print(f\"Downloading all .tif files from: {source_path}\")\n","\n","# DOWNLOAD FILES\n","!gsutil -m cp \"{source_path}*.tif\" {local_path}\n","print(\"\\nDownloaded files:\")\n","!ls -lh /content/data/*.tif\n"]},{"cell_type":"markdown","metadata":{"id":"67rJryJzk4pR"},"source":["# GET RANDOM POINTS\n"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1485,"status":"ok","timestamp":1763492367548,"user":{"displayName":"Saad Kaka","userId":"12542036726510373387"},"user_tz":300},"id":"f3402a95","outputId":"6379ddde-7679-445a-abd1-eb4854b49451"},"outputs":[{"output_type":"stream","name":"stdout","text":["ON data:\n","  Width: 6034 pixels\n","  Height: 16300 pixels\n","  Bands: 1\n","  Data Type: int32\n","  Geographical Bounding Box: BoundingBox(left=-84.10009723621279, bottom=47.210330936202574, right=-82.47396690889963, top=51.60309267554703)\n","  CRS: EPSG:4326\n","\n"," Labels and counts in ON.tif:\n","  Label 0: 16,099,851 pixels\n","  Label 1: 12,364,188 pixels\n","  Label 2: 1,149,204 pixels\n","  Label 3: 21,506,132 pixels\n","  Label 4: 2,669 pixels\n","  Label 5: 3,569,203 pixels\n","  Label 6: 42,325,005 pixels\n","  Label 7: 195,949 pixels\n","  Label 8: 11,600 pixels\n","  Label 9: 17,329 pixels\n","  Label 10: 581,764 pixels\n","  Label 11: 31,916 pixels\n","  Label 12: 4,680 pixels\n","  Label 13: 494,710 pixels\n","Total labeled pixels: 98,354,200\n"]}],"source":["import rasterio\n","import numpy as np\n","\n","region = \"ON\"\n","tiff = f'/content/data/{region}.tif'\n","\n","# GET ALL LABELS WITHIN a .TIF FILE\n","print(f\"{region} data:\")\n","with rasterio.open(tiff) as src:\n","    width = src.width\n","    height = src.height\n","    bands = src.count\n","    dtype = src.profile['dtype']\n","    bounds = src.bounds\n","\n","    print(f\"  Width: {width} pixels\")\n","    print(f\"  Height: {height} pixels\")\n","    print(f\"  Bands: {bands}\")\n","    print(f\"  Data Type: {dtype}\")\n","    print(f\"  Geographical Bounding Box: {bounds}\")\n","    print(f\"  CRS: {src.crs}\")\n","\n","    labels_array = src.read(1)\n","    unique_labels, counts = np.unique(labels_array[np.isfinite(labels_array)], return_counts=True)\n","\n","    print(\"\\n Labels and counts in ON.tif:\")\n","    for label, count in zip(unique_labels, counts):\n","        print(f\"  Label {int(label)}: {count:,} pixels\")\n","    total_pixels = np.sum(counts)\n","    print(f\"Total labeled pixels: {total_pixels:,}\")\n"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6340,"status":"ok","timestamp":1763492820450,"user":{"displayName":"Saad Kaka","userId":"12542036726510373387"},"user_tz":300},"id":"K8cjAg1Rr_Uw","outputId":"a629c7e3-e4f5-454d-b68a-b710dfcf80c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Total points sampled: 2250\n","/content/BC.tif_points.csv : 250 points\n","/content/MB.tif_points.csv : 750 points\n","/content/ON.tif_points.csv : 1250 points\n"]}],"source":["import rasterio\n","import random\n","import math\n","from shapely.geometry import Point, Polygon\n","from collections import defaultdict\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","\n","def get_points(polygon, tiff_path, cdict, hsize=64, seed=42, attempts=10000):\n","    random.seed(seed)\n","    sampled_points = []\n","\n","    with rasterio.open(tiff_path) as src:\n","        arr = src.read(1)\n","        height, width = arr.shape\n","        transform = src.transform\n","        crs = src.crs\n","        minx, miny, maxx, maxy = polygon.bounds\n","\n","        # Safe pixel bounds for patch extraction\n","        col_min, row_max = ~transform * (minx, maxy)\n","        col_max, row_min = ~transform * (maxx, miny)\n","        px_min, px_max = int(math.ceil(col_min + hsize)), int(math.floor(col_max - hsize))\n","        py_min, py_max = int(math.ceil(row_max + hsize)), int(math.floor(row_min - hsize))\n","        px_min, py_min = max(px_min, hsize), max(py_min, hsize)\n","        px_max, py_max = min(px_max, width - 1 - hsize), min(py_max, height - 1 - hsize)\n","\n","        if px_min > px_max or py_min > py_max:\n","            print(f\"[WARN] Polygon too small for {2*hsize}px patches in {tiff_path}\")\n","            return []\n","\n","        # Filter valid classes\n","        valid_labels = set(np.unique(arr[np.isfinite(arr)]))\n","        quotas = {k: int(v) for k, v in cdict.items() if v > 0 and k in valid_labels}\n","\n","        if not quotas:\n","            print(f\"[WARN] No valid class quotas for {tiff_path}\")\n","            return []\n","\n","        # Random sampling\n","        for _ in range(attempts):\n","            if all(v <= 0 for v in quotas.values()):\n","                break\n","\n","            px, py = random.randint(px_min, px_max), random.randint(py_min, py_max)\n","            x, y = transform * (px, py)\n","\n","            if not polygon.contains(Point(x, y)):\n","                continue\n","\n","            label = int(arr[py, px])\n","            if label in quotas and quotas[label] > 0:\n","                sampled_points.append((x, y, label, crs, tiff_path))\n","                quotas[label] -= 1\n","\n","        # Report unmet quotas\n","        unmet = {k: v for k, v in quotas.items() if v > 0}\n","        if unmet:\n","            print(f\"[WARN] Unmet quotas in {tiff_path}: {unmet}\")\n","\n","    return sampled_points\n","\n","\n","tiff_info = [\n","    (\"/content/data/BC.tif\", {0: 0, 1: 0, 2: 0, 3: 0, 4: 250}),\n","    (\"/content/data/MB.tif\", {0: 0, 1: 0, 2: 500, 3: 250, 4: 250}),\n","    (\"/content/data/ON.tif\", {0: 500, 1: 500, 2: 0, 3: 250, 4: 0}),\n","]\n","\n","hsize, attempts = 64, 200000\n","output_dir = \"/content/\"\n","\n","all_points = []\n","\n","for path, cdict in tiff_info:\n","    with rasterio.open(path) as src:\n","        poly = Polygon.from_bounds(*src.bounds)\n","    points = get_points(poly, path, cdict, hsize, seed=42, attempts=attempts)\n","    all_points.extend(points)\n","\n","df = pd.DataFrame(all_points, columns=[\"world_x\", \"world_y\", \"label\", \"src_crs\", \"source_file\"])\n","print(f\"\\nTotal points sampled: {len(df)}\")\n","\n","for file, group in df.groupby(\"source_file\"):\n","    csv_path = os.path.join(output_dir, f\"{os.path.basename(file)}_points.csv\")\n","    group[[\"world_x\", \"world_y\", \"label\"]].to_csv(csv_path, index=False)\n","    print(f\"{csv_path} : {len(group)} points\")\n","\n"]},{"cell_type":"code","source":["!gsutil cp /content/ON.tif_points.csv gs://saadwetlands-bucket/pixel_data\n","!gsutil cp /content/MB.tif_points.csv gs://saadwetlands-bucket/pixel_data\n","!gsutil cp /content/BC.tif_points.csv gs://saadwetlands-bucket/pixel_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uqhoTVvYe6xl","executionInfo":{"status":"ok","timestamp":1763478214166,"user_tz":300,"elapsed":6452,"user":{"displayName":"Saad Kaka","userId":"12542036726510373387"}},"outputId":"3c349876-fe4c-41dd-e946-2603ba55ba4a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Copying file:///content/ON.tif_points.csv [Content-Type=text/csv]...\n","/ [1 files][ 47.7 KiB/ 47.7 KiB]                                                \n","Operation completed over 1 objects/47.7 KiB.                                     \n","Copying file:///content/MB.tif_points.csv [Content-Type=text/csv]...\n","/ [1 files][ 28.8 KiB/ 28.8 KiB]                                                \n","Operation completed over 1 objects/28.8 KiB.                                     \n","Copying file:///content/BC.tif_points.csv [Content-Type=text/csv]...\n","/ [1 files][  5.2 KiB/  5.2 KiB]                                                \n","Operation completed over 1 objects/5.2 KiB.                                      \n"]}]},{"cell_type":"markdown","source":["# SERIALIZE TENSERFLOW\n"],"metadata":{"id":"tCG8IXogLo14"}},{"cell_type":"code","source":["import apache_beam as beam\n","from apache_beam.options.pipeline_options import (\n","    PipelineOptions, StandardOptions, SetupOptions, WorkerOptions\n",")\n","import tensorflow as tf\n","import ee\n","import numpy as np\n","import rasterio\n","from rasterio.windows import Window\n","import tempfile\n","import urllib.request\n","import pandas as pd\n","import os\n","import subprocess\n","import logging\n","\n","\n","project = \"saadwetlands\"\n","bucket = \"saadwetlands-bucket\"\n","YEAR = 2024\n","PATCH_SIZE = 128\n","PIXEL_SIZE = 30\n","\n","REGION = \"BC\"\n","label_tif = f\"gs://{bucket}/pixel_data/{REGION}.tif\"\n","TFRECORD_OUTPUT_PREFIX = f\"gs://{bucket}/output/patches/{REGION}/\"\n","csv_path = f\"gs://{bucket}/pixel_data/{REGION}.tif_points.csv\"\n","\n","KEY_GCS_PATH = f\"gs://{bucket}/keys/ee-dataflow-worker-key.json\"\n","LOCAL_KEY_PATH = \"/tmp/ee-dataflow-worker-key.json\"\n","\n","logging.basicConfig(level=logging.INFO)\n","_LOGGER = logging.getLogger(__name__)\n","\n","def get_label_patch(lon, lat):\n","    \"\"\"Read 128x128 patch from label GeoTIFF\"\"\"\n","    try:\n","        with rasterio.Env():\n","            with rasterio.open(label_tif) as src:\n","                row, col = src.index(lon, lat)\n","                half = PATCH_SIZE // 2\n","                window = Window(col - half, row - half, PATCH_SIZE, PATCH_SIZE)\n","                patch = src.read(1, window=window)\n","        return patch\n","    except Exception as e:\n","        _LOGGER.error(f\"Failed to get label patch for ({lon},{lat}): {e}\")\n","        return None\n","\n","def fetch_embedding_patch(embedding_image, lon, lat):\n","    \"\"\"Download embedding patch from Earth Engine\"\"\"\n","    try:\n","        bands = embedding_image.bandNames()\n","        image = embedding_image.select(bands)\n","        point = ee.Geometry.Point([lon, lat])\n","        region = point.buffer(PIXEL_SIZE * PATCH_SIZE / 2).bounds()\n","        url = image.getDownloadURL({\n","            \"region\": region.getInfo()['coordinates'],\n","            \"dimensions\": [PATCH_SIZE, PATCH_SIZE],\n","            \"format\": \"GEO_TIFF\"\n","        })\n","        with tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False) as tmpfile:\n","            urllib.request.urlretrieve(url, tmpfile.name)\n","            with rasterio.open(tmpfile.name) as src:\n","                patch = np.transpose(src.read(), (1, 2, 0))\n","        os.remove(tmpfile.name)\n","        return patch\n","    except Exception as e:\n","        _LOGGER.error(f\"Failed to fetch embedding for ({lon},{lat}): {e}\")\n","        return None\n","\n","def _bytes_feature(value):\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","def serialize_example(label_patch, embedding_patch):\n","    feature = {\n","        'embedding': _bytes_feature(embedding_patch.astype(np.float32).tobytes()),\n","        'label': _bytes_feature(label_patch.astype(np.int32).tobytes()),\n","        'height': _int64_feature(label_patch.shape[0]),\n","        'width': _int64_feature(label_patch.shape[1]),\n","        'bands': _int64_feature(embedding_patch.shape[2])\n","    }\n","    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n","    return example_proto.SerializeToString()\n","\n","class GeneratePatchDoFn(beam.DoFn):\n","    def setup(self):\n","        import ee\n","        import os\n","        import tempfile\n","        from google.cloud import storage\n","\n","        # Worker local path for the key\n","        key_path = '/tmp/ee-dataflow-worker-key.json'\n","\n","        # Download key from GCS\n","        client = storage.Client()\n","        bucket = client.bucket('saadwetlands-bucket')\n","        blob = bucket.blob('keys/ee-dataflow-worker-key.json')\n","        blob.download_to_filename(key_path)\n","\n","        # Initialize Earth Engine with the service account credentials\n","        credentials = ee.ServiceAccountCredentials(\n","            'ee-dataflow-worker@saadwetlands.iam.gserviceaccount.com',\n","            key_path\n","        )\n","        ee.Initialize(credentials)\n","\n","        # Load embedding image\n","        self.embedding_image = ee.ImageCollection(\"GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL\") \\\n","                                .filterDate(f\"{YEAR}-01-01\", f\"{YEAR}-12-31\") \\\n","                                .mosaic()\n","    def process(self, row):\n","        lon, lat = float(row['world_x']), float(row['world_y'])\n","        _LOGGER.info(f\"Processing point: ({lon}, {lat})\")\n","\n","        label_patch = get_label_patch(lon, lat)\n","        embedding_patch = fetch_embedding_patch(self.embedding_image, lon, lat)\n","\n","        if label_patch is None or embedding_patch is None:\n","            _LOGGER.warning(f\"Skipping point ({lon},{lat}) due to missing data.\")\n","            return\n","\n","        _LOGGER.info(f\"Generated patches for ({lon}, {lat})\")\n","        yield serialize_example(label_patch, embedding_patch)\n","\n","options = PipelineOptions(\n","    runner='DataflowRunner',\n","    project=project,\n","    job_name='wetland-patch-pipeline',\n","    staging_location=f'gs://{bucket}/staging',\n","    temp_location=f'gs://{bucket}/temp',\n","    region='us-central1',\n","    requirements_file='requirements.txt'\n",")\n","\n","# Worker configuration\n","worker_options = options.view_as(WorkerOptions)\n","worker_options.machine_type = 'n1-standard-4'\n","worker_options.num_workers = 5\n","worker_options.max_num_workers = 20\n","\n","options.view_as(StandardOptions).runner = 'DataflowRunner'\n","options.view_as(SetupOptions).save_main_session = True\n","\n","# Read CSV from GCS\n","df = pd.read_csv(csv_path)\n","rows_list = df.to_dict(orient='records')\n","\n","# Run Beam Pipeline\n","with beam.Pipeline(options=options) as pipeline:\n","    (\n","        pipeline\n","        | \"Create Rows\" >> beam.Create(rows_list)\n","        | \"Generate Patches\" >> beam.ParDo(GeneratePatchDoFn())\n","        | \"Write TFRecords\" >> beam.io.WriteToTFRecord(\n","            file_path_prefix=TFRECORD_OUTPUT_PREFIX,\n","            file_name_suffix=\".tfrecord\",\n","            coder=beam.coders.BytesCoder()\n","        )\n","    )\n","\n","print(\"Pipeline submitted! Check the Dataflow console for progress.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"d-WCQhM2f1h7","executionInfo":{"status":"ok","timestamp":1763491991008,"user_tz":300,"elapsed":646290,"user":{"displayName":"Saad Kaka","userId":"12542036726510373387"}},"outputId":"84b2688e-c548-4ccb-dbaa-6ec6ded19d7c"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-f585256f-4762-4329-8f16-bed88f7e9315.json']\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    div.alert {\n","      white-space: pre-line;\n","    }\n","  </style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n","            <div class=\"alert alert-info\">No cache_root detected. Defaulting to staging_location gs://saadwetlands-bucket/staging for cache location.</div>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:apache_beam.options.pipeline_options:Unparseable argument: -f\n","WARNING:apache_beam.options.pipeline_options:Unparseable argument: /root/.local/share/jupyter/runtime/kernel-f585256f-4762-4329-8f16-bed88f7e9315.json\n","WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n","WARNING:apache_beam.options.pipeline_options:Unparseable argument: -f\n","WARNING:apache_beam.options.pipeline_options:Unparseable argument: /root/.local/share/jupyter/runtime/kernel-f585256f-4762-4329-8f16-bed88f7e9315.json\n","WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n","WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n","WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n","WARNING:apache_beam.runners.dataflow.dataflow_runner:2025-11-18T18:47:38.233Z: JOB_MESSAGE_WARNING: Autoscaling: Startup of the worker pool in us-central1 reached 3 workers, but the goal was 5 workers. The service will retry. Please refer to https://cloud.google.com/dataflow/docs/guides/common-errors#worker-pool-failure for help troubleshooting. QUOTA_EXCEEDED: Instance 'wetland-patch-pipeline-11181046-cpja-harness-8c2w' creation failed: Quota 'CPUS_ALL_REGIONS' exceeded.  Limit: 12.0 globally.\n"]},{"output_type":"stream","name":"stdout","text":["Pipeline submitted! Check the Dataflow console for progress.\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"12LiDDmUkTPyohFut6WcoZBxZsvL3xbdr","authorship_tag":"ABX9TyMwF1uckbGCEUtytOooSWwl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}